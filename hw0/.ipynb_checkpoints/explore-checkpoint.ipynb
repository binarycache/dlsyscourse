{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9cb3d66-42f9-45e1-abf4-21661357e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src import simple_ml\n",
    "# Example of target with class indices\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4ffa62-ee98-4a11-8e2a-4491c477d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(img):\n",
    "    \"\"\"\n",
    "    img: list with len = 784\n",
    "    An example image of MNIST dataset either train or test\n",
    "    \"\"\"\n",
    "    # Convert to numpy array\n",
    "    img = np.array(img)\n",
    "    # Reshape to 28x28 image to plot using matplotlib\n",
    "    img = img.reshape(28,28)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f981a634-57b0-475d-ba22-3bdce4ff2c99",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trying reading binary (rb) mode\n",
    "# ubyte is unsigned byte\n",
    "# idx3 means dimensions like n1xn2xn3; for MNIST train its 60,000 x 28 x 28\n",
    "# MNIST test is 10,000 x 28 x 28, we will convert this into 10,000 x 784\n",
    "\n",
    "path = 'data/t10k-images-idx3-ubyte.gz'\n",
    "with gzip.open(path,'rb') as f:\n",
    "    data = f.read() # returns a bytes object\n",
    "\n",
    "#### Format of the test images file\n",
    "# Train SET IMAGE FILE (train-images-idx3-ubyte):\n",
    "# |[offset] | [type]     |     [value]     |     [description]\n",
    "# 0000     32 bit integer  0x00000803(2051) magic number\n",
    "# 0004     32 bit integer  10000            number of images\n",
    "# 0008     32 bit integer  28               number of rows\n",
    "# 0012     32 bit integer  28               number of columns\n",
    "# 0016     unsigned byte   ??               pixel\n",
    "# 0017     unsigned byte   ??               pixel\n",
    "# ........\n",
    "# xxxx     unsigned byte   ??               pixel\n",
    "\n",
    "# For reading first 16 bytes, containing 4 bytes for magic number, 4 for #images, 4 for #rows and 4 for #cols \n",
    "meta_data = struct.iter_unpack('>I',data[0:16])\n",
    "\n",
    "magic_number = next(meta_data)\n",
    "n_images= next(meta_data)\n",
    "n_rows = next(meta_data)\n",
    "n_cols = next(meta_data)\n",
    "\n",
    "magic_number, n_images, n_rows, n_cols\n",
    "\n",
    "pixels = list(struct.iter_unpack('>B',data[16:]))\n",
    "\n",
    "len(list(pixels)) # 10000 x 784\n",
    "\n",
    "images = []\n",
    "n_pixels = n_rows[0] * n_cols[0]\n",
    "for i in range(n_images[0]):\n",
    "    images.append(pixels[i * n_pixels: i * n_pixels + n_pixels])\n",
    "\n",
    "assert len(images)==10000, \"Make sure there are 10,000 images in the test set\"\n",
    "\n",
    "visualize_image(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc50fc-91a5-4f9a-817d-584462634725",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trying reading binary (rb) mode\n",
    "# ubyte is unsigned byte\n",
    "# idx3 means dimensions like n1xn2xn3; for MNIST train its 60,000 x 28 x 28\n",
    "# MNIST test is 10,000 x 28 x 28, we will convert this into 10,000 x 784\n",
    "\n",
    "path = 'data/train-images-idx3-ubyte.gz'\n",
    "with gzip.open(path,'rb') as f:\n",
    "    data = f.read() # returns a bytes object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb0579c-53a2-4118-b8a2-d60ca3921d97",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_data = struct.iter_unpack('>I',data[0:16])\n",
    "magic_number, n_images, n_rows, n_cols = meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beabb3a1-baf9-4c3d-88a3-bd18080ace59",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "magic_number,n_images,n_rows,n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6648dd-f9cf-4184-95e3-c182b2029626",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Format of the test images file\n",
    "# Train SET IMAGE FILE (train-images-idx3-ubyte):\n",
    "# |[offset] | [type]     |     [value]     |     [description]\n",
    "# 0000     32 bit integer  0x00000803(2051) magic number\n",
    "# 0004     32 bit integer  10000            number of images\n",
    "# 0008     32 bit integer  28               number of rows\n",
    "# 0012     32 bit integer  28               number of columns\n",
    "# 0016     unsigned byte   ??               pixel\n",
    "# 0017     unsigned byte   ??               pixel\n",
    "# ........\n",
    "# xxxx     unsigned byte   ??               pixel\n",
    "\n",
    "# For reading first 16 bytes, containing 4 bytes for magic number, 4 for #images, 4 for #rows and 4 for #cols \n",
    "meta_data = struct.iter_unpack('>I',data[0:16])\n",
    "\n",
    "magic_number = next(meta_data)\n",
    "n_images= next(meta_data)\n",
    "n_rows = next(meta_data)\n",
    "n_cols = next(meta_data)\n",
    "\n",
    "magic_number, n_images, n_rows, n_cols\n",
    "\n",
    "pixels = list(struct.iter_unpack('>B',data[16:]))\n",
    "\n",
    "len(list(pixels)) # 10000 x 784\n",
    "\n",
    "images = []\n",
    "n_pixels = n_rows[0] * n_cols[0]\n",
    "for i in range(n_images[0]):\n",
    "    images.append(pixels[i * n_pixels: i * n_pixels + n_pixels])\n",
    "\n",
    "assert len(images)==60000, \"Make sure there are 10,000 images in the test set\"\n",
    "\n",
    "visualize_image(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e825d-414e-4c5b-8525-342b61355c20",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trying reading binary (rb) mode\n",
    "# ubyte is unsigned byte\n",
    "# idx3 means dimensions like n1xn2xn3; for MNIST train its 60,000 x 28 x 28\n",
    "# MNIST test is 10,000 x 28 x 28, we will convert this into 10,000 x 784\n",
    "\n",
    "path = 'data/train-labels-idx1-ubyte.gz'\n",
    "with gzip.open(path,'rb') as f:\n",
    "    data = f.read() # returns a bytes object\n",
    "\n",
    "#### Format of the test images file\n",
    "# Train SET label FILE (train-labels-idx1-ubyte):\n",
    "# [offset] [type]          [value]          [description]\n",
    "# 0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n",
    "# 0004     32 bit integer  10000            number of items\n",
    "# 0008     unsigned byte   ??               label\n",
    "# 0009     unsigned byte   ??               label\n",
    "# ........\n",
    "# xxxx     unsigned byte   ??               label\n",
    "# The labels values are 0 to 9.\n",
    "\n",
    "# For reading first 16 bytes, containing 4 bytes for magic number, 4 for #images, 4 for #rows and 4 for #cols \n",
    "meta_data = struct.iter_unpack('>I',data[0:8])\n",
    "\n",
    "magic_number = next(meta_data)\n",
    "n_labels = next(meta_data)\n",
    "\n",
    "\n",
    "train_labels = [label[0] for label in struct.iter_unpack('>B',data[8:])]\n",
    "\n",
    "assert len(train_labels)==n_labels[0], f\"Make sure there are {n_labels} labels in the test set, you currently have {len(train_labels)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca8ae0-f298-4a3f-926d-6b33056cb4ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trying reading binary (rb) mode\n",
    "# ubyte is unsigned byte\n",
    "# idx1 means dimensions like n1; for MNIST train its 60,000 for train\n",
    "# MNIST test is 10,000 x 1\n",
    "\n",
    "path = 'data/t10k-labels-idx1-ubyte.gz'\n",
    "with gzip.open(path,'rb') as f:\n",
    "    data = f.read() # returns a bytes object\n",
    "\n",
    "#### Format of the test images file\n",
    "# Test SET label FILE (test-labels-idx1-ubyte):\n",
    "# [offset] [type]          [value]          [description]\n",
    "# 0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n",
    "# 0004     32 bit integer  10000            number of items\n",
    "# 0008     unsigned byte   ??               label\n",
    "# 0009     unsigned byte   ??               label\n",
    "# ........\n",
    "# xxxx     unsigned byte   ??               label\n",
    "# The labels values are 0 to 9.\n",
    "\n",
    "# For reading first 16 bytes, containing 4 bytes for magic number, 4 for #images, 4 for #rows and 4 for #cols \n",
    "meta_data = struct.iter_unpack('>I',data[0:8])\n",
    "\n",
    "magic_number = next(meta_data)\n",
    "n_labels = next(meta_data)\n",
    "\n",
    "\n",
    "test_labels = [label[0] for label in struct.iter_unpack('>B',data[8:])]\n",
    "\n",
    "assert len(test_labels)==n_labels[0], f\"Make sure there are {n_labels} labels in the test set, you currently have {len(train_labels)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daabe02-63de-455e-813d-85a941fe9976",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_images(image_filename:str)->list:\n",
    "    print(f\"Working on {image_filename}\")\n",
    "    with gzip.open(image_filename,'rb') as f:\n",
    "        data = f.read() # returns a bytes object\n",
    "\n",
    "    #### Format of the test images file\n",
    "    # Train/Test SET IMAGE FILE (train[t10k]-images-idx3-ubyte):\n",
    "    # |[offset] | [type]     |     [value]     |     [description]\n",
    "    # 0000     32 bit integer  0x00000803(2051) magic number\n",
    "    # 0004     32 bit integer  60000(10000)     number of train(test)images\n",
    "    # 0008     32 bit integer  28               number of rows\n",
    "    # 0012     32 bit integer  28               number of columns\n",
    "    # 0016     unsigned byte   ??               pixel\n",
    "    # 0017     unsigned byte   ??               pixel\n",
    "    # ........\n",
    "    # xxxx     unsigned byte   ??               pixel\n",
    "\n",
    "    # For reading first 16 bytes, containing 4 bytes for magic number, 4 for #images, 4 for #rows and 4 for #cols \n",
    "    meta_data = struct.iter_unpack('>I',data[0:16])\n",
    "\n",
    "    magic_number, n_images, n_rows, n_cols  = meta_data\n",
    "\n",
    "    pixels = [pix[0] for pix in struct.iter_unpack('>B',data[16:])]\n",
    "\n",
    "    images = []\n",
    "    n_pixels = n_rows[0] * n_cols[0]\n",
    "    n_images = n_images[0]\n",
    "    assert len(list(pixels))==n_images*n_pixels # 60000(10000) x 784\n",
    "    \n",
    "    for i in range(n_images):\n",
    "        images.append(pixels[i * n_pixels: i * n_pixels + n_pixels])\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda5dc2-97a1-4c59-afff-72b2ad758b0e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_labels(label_filename:str)->list:\n",
    "    print(f\"Working on {label_filename}\")\n",
    "    with gzip.open(label_filename,'rb') as f:\n",
    "        data = f.read() # returns a bytes object\n",
    "\n",
    "    #### Format of the test images file\n",
    "    # Train/test SET label FILE (train(t10k)-labels-idx1-ubyte):\n",
    "    # [offset] [type]          [value]          [description]\n",
    "    # 0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n",
    "    # 0004     32 bit integer  60000(10000)     number of items\n",
    "    # 0008     unsigned byte   ??               label\n",
    "    # 0009     unsigned byte   ??               label\n",
    "    # ........\n",
    "    # xxxx     unsigned byte   ??               label\n",
    "    # The labels values are 0 to 9.\n",
    "\n",
    "    # For reading first 8 bytes, containing 4 bytes for magic number, 4 for #labels\n",
    "    meta_data = struct.iter_unpack('>I',data[0:8])\n",
    "\n",
    "    magic_number = next(meta_data)\n",
    "    n_labels = next(meta_data)\n",
    "\n",
    "    labels = [label[0] for label in struct.iter_unpack('>B',data[8:])]\n",
    "\n",
    "    assert len(labels)==n_labels[0], f\"Make sure there are {n_labels} labels in the test set,\\\n",
    "                                       you currently have {len(labels)}\"\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44cb48-3151-4d50-97d3-c175ae0ce21f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_mnist(image_filename, label_filename):\n",
    "    \"\"\" Read an images and labels file in MNIST format.  See this page:\n",
    "    http://yann.lecun.com/exdb/mnist/ for a description of the file format.\n",
    "\n",
    "    Args:\n",
    "        image_filename (str): name of gzipped images file in MNIST format\n",
    "        label_filename (str): name of gzipped labels file in MNIST format\n",
    "\n",
    "    Returns:\n",
    "        Tuple (X,y):\n",
    "            X (numpy.ndarray[np.float32]): 2D numpy array containing the loaded\n",
    "                data.  The dimensionality of the data should be\n",
    "                (num_examples x input_dim) where 'input_dim' is the full\n",
    "                dimension of the data, e.g., since MNIST images are 28x28, it\n",
    "                will be 784.  Values should be of type np.float32, and the data\n",
    "                should be normalized to have a minimum value of 0.0 and a\n",
    "                maximum value of 1.0.\n",
    "\n",
    "            y (numpy.ndarray[dypte=np.uint8]): 1D numpy array containing the\n",
    "                labels of the examples.  Values should be of type np.uint8 and\n",
    "                for MNIST will contain the values 0-9.\n",
    "    \"\"\"\n",
    "    ### BEGIN YOUR CODE\n",
    "    if  \"train\" in image_filename:\n",
    "        assert \"train-labels\" in label_filename, \"Please pass labels for train images only.\"\n",
    "        images = parse_images(image_filename)\n",
    "        labels = parse_labels(label_filename)\n",
    "        train_images = np.array(images, dtype=np.float32)\n",
    "        # normalize the images between 0 and 1\n",
    "        #train_images = train_images/np.linalg.norm(train_images)\n",
    "        train_labels = np.array(labels, dtype=np.uint8)\n",
    "        return (train_images, train_labels)\n",
    "    \n",
    "    if  \"test\" in image_filename:\n",
    "        assert \"t10k-labels\" in label_filename, \"Please pass labels for test images only.\"\n",
    "        images = parse_images(image_filename)\n",
    "        labels = parse_labels(label_filename)\n",
    "        #test_images = np.array(images, dtype=np.float32)\n",
    "        # normalize the images between 0 and 1\n",
    "        test_images = test_images/np.linalg.norm(test_images)\n",
    "        test_labels = np.array(labels, dtype=np.uint8)\n",
    "        return (test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d787a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = simple_ml.parse_mnist(\"data/train-images-idx3-ubyte.gz\",\n",
    "            \"data/train-labels-idx1-ubyte.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55a993f-e987-4e1b-b6ba-b43275bb16b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e8a62d4-48c9-40e0-9e9a-ab3f472b105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros((y.shape[0], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877eb818-be06-456e-8ba5-751fa2b16a7b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Z = np.random.randn(y.shape[0], 10)\n",
    "\n",
    "# Z.shape, y.shape\n",
    "\n",
    "# (np.argmax(Z, axis=1)==y).shape\n",
    "\n",
    "# np.argmax(Z, axis=1).shape, np.max(y)\n",
    "\n",
    "# np.mean(np.log(np.sum(np.exp(Z),axis=1)))\n",
    "\n",
    "# np.mean(np.argmax(Z, axis=1)==y)\n",
    "\n",
    "# np.mean(np.log(np.sum(np.exp(Z),axis=1))) \n",
    "\n",
    "# loss = np.mean(np.log(np.sum(np.exp(Z),axis=1)) - ((np.argmax(Z, axis=1)+1==y+1)))\n",
    "\n",
    "# loss\n",
    "\n",
    "# np.mean(loss, dtype=np.float32)\n",
    "\n",
    "# e_x = np.exp(Z - np.max(Z))\n",
    "# softmax = np.log(e_x / e_x.sum())\n",
    "\n",
    "# np.mean(np.mean(softmax) - (np.argmax(Z, axis=1)==y))\n",
    "\n",
    "# Z = np.random.randn(y.shape[0], 10)\n",
    "\n",
    "# np.mean(np.log(np.sum(np.exp(Z),axis=1)) - (np.argmax(Z, axis=1)==y))\n",
    "\n",
    "# np.argmax(Z, axis=1).shape, y.shape\n",
    "\n",
    "# type(y), type(np.argmax(Z,axis=0))\n",
    "\n",
    "# np.mean(np.log(np.sum(np.exp(Z),axis=1)) - np.equal(np.argmax(Z, axis=1),y))\n",
    "\n",
    "# np.sum(Z,axis=1).shape\n",
    "\n",
    "# np.argmax(Z[0:10],axis=1)\n",
    "\n",
    "# max_Z = np.max(Z)\n",
    "# max_Z\n",
    "\n",
    "# exp_Z = np.exp(Z - max_Z)\n",
    "# exp_Z.shape\n",
    "\n",
    "# sum_exp_Z = np.sum(exp_Z,axis=0)\n",
    "# log_sum_exp_Z = np.log(sum_exp_Z)\n",
    "# max_plus_log_sum_exp_Z = max_Z + log_sum_exp_Z\n",
    "# max_plus_log_sum_exp_Z.shape\n",
    "\n",
    "# Z.max()\n",
    "\n",
    "# max_plus_log_sum_exp_Z\n",
    "\n",
    "# log_probs = Z - max_plus_log_sum_exp_Z\n",
    "\n",
    "# log_probs\n",
    "\n",
    "# np.mean(np.log(np.sum(np.exp(Z),axis=1)) - (np.argmax(Z, axis=1)==y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897bacc-06ff-45f0-a8ac-07d0fc94fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    exps = np.exp(X)\n",
    "    return exps / np.sum(exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a1365-d4e6-4af0-af37-758779a4d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_softmax(X):\n",
    "    exps = np.exp(X - np.max(X))\n",
    "    return exps / np.sum(exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0598cf-dac5-4b38-b4cb-b973be3120bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = y.shape[0]\n",
    "p = softmax(Z)\n",
    "# We use multidimensional array indexing to extract \n",
    "# softmax probability of the correct label for each sample.\n",
    "# Refer to https://docs.scipy.org/doc/numpy/user/basics.indexing.html#indexing-multi-dimensional-arrays for understanding multidimensional array indexing.\n",
    "log_likelihood = -np.log(p[range(m),y])\n",
    "loss = np.sum(log_likelihood) / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e271a4-3ced-4a06-889b-a0c5be6816f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b0f37f-40e7-4266-8a77-25c7c90141be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nll_loss(log_softmax(input, 1), target, weight, size_average, ignore_index, reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5638f74c-a5bc-4425-99fb-88b06719f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference:\n",
    "#https://stackoverflow.com/questions/70202761/manually-computing-cross-entropy-loss-in-pytorch\n",
    "class CrossEntropyLossManual:\n",
    "    \"\"\"\n",
    "    Z is the vector with shape (batch_size,C)\n",
    "    y shape is the same (batch_size), whose entries are integers from 0 to C-1\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def __call__(self, Z, y):\n",
    "        loss = 0.\n",
    "        n_batch, n_class = Z.shape\n",
    "        #numerator, denominator, softmax, log_softmax = [],[],[],[]\n",
    "        #print(n_batch,n_class)\n",
    "        for z1, y1 in zip(Z, y):\n",
    "            #print(z1,y1)\n",
    "            class_index = int(y1.item())\n",
    "            # numerator.append(torch.exp(z1[class_index]))\n",
    "            # denominator.append(torch.exp(z1).sum())\n",
    "            # softmax.append(torch.exp(z1[class_index])/(torch.exp(z1).sum()))\n",
    "            # log_softmax.append(torch.log(torch.exp(z1[class_index])/(torch.exp(z1).sum())))\n",
    "            loss = loss + torch.log(torch.exp(z1[class_index])/(torch.exp(z1).sum()))\n",
    "        # print(f\"Numerator calcualted by loss_manual is {numerator}\")\n",
    "        # print(f\"Denominator calcualted by loss_manual is {denominator}\")\n",
    "        # print(f\"Softmax calcualted by loss_manual is {softmax}\")\n",
    "        # print(f\"Log-Softmax calcualted by loss_manual is {log_softmax}\")\n",
    "        # print(f\"Loss before average by loss_manual is {loss}\")\n",
    "        loss = - loss/n_batch\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b8382fd-d00d-4619-9439-860b4189eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_numpy(input, target):\n",
    "    numerator = np.exp(input[range(input.shape[0]),target])\n",
    "    #print(f\"Numerator calcualted by loss_numpy is {numerator}\")\n",
    "    denominator = np.sum(np.exp(input), axis=1)\n",
    "    #print(f\"Denominator calcualted by loss_numpy is {denominator}\")\n",
    "    softmax = numerator/denominator\n",
    "    #print(f\"Softmax calcualted by loss_numpy is {softmax}\")\n",
    "    log_softmax = np.log(softmax)\n",
    "    #print(f\"Log-Softmax calcualted by loss_numpy is {log_softmax}\")\n",
    "    loss = np.mean(log_softmax)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6796c8a5-ca1b-45f8-88f4-26aa0257ee7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(3, 5)\n",
    "target = torch.empty(3, dtype = torch.long).random_(5)\n",
    "print(input.shape,target.shape)\n",
    "input_np = input.numpy()\n",
    "target_np = target.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79ca8452-6ce4-4e0c-a481-d7d5c9f48994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss via manual: \n",
      " tensor(1.7306)\n",
      "Cross Entropy Loss via numpy: \n",
      " -1.7306296\n"
     ]
    }
   ],
   "source": [
    "loss_manual = CrossEntropyLossManual()\n",
    "output_manual = loss_manual(input, target)\n",
    "output_numpy = loss_numpy(input_np,target_np)\n",
    "print('Cross Entropy Loss via manual: \\n', output_manual)\n",
    "print('Cross Entropy Loss via numpy: \\n', output_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7b864cd-6e55-41df-964a-535c39e58d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "  tensor([[0.4009, 0.5387, 0.2455, 0.1033, 0.6917],\n",
      "        [0.5332, 0.1734, 0.7952, 0.8132, 0.7162],\n",
      "        [0.2048, 0.5878, 0.9979, 0.6212, 0.8195]])\n",
      "target:\n",
      "  tensor([2, 0, 1])\n",
      "Cross Entropy Loss via pytorch: \n",
      " tensor(1.7306)\n",
      "Cross Entropy Loss via manual: \n",
      " tensor(1.7306)\n",
      "Cross Entropy Loss via numpy: \n",
      " -1.7306296\n"
     ]
    }
   ],
   "source": [
    "loss_manual = CrossEntropyLossManual()\n",
    "loss_pytorch = nn.CrossEntropyLoss()\n",
    "output_pytorch = loss_pytorch(input, target)\n",
    "output_manual = loss_manual(input, target)\n",
    "output_numpy = loss_numpy(input_np,target_np)\n",
    "print('input:\\n ', input)\n",
    "print('target:\\n ', target)\n",
    "print('Cross Entropy Loss via pytorch: \\n', output_pytorch)\n",
    "print('Cross Entropy Loss via manual: \\n', output_manual)\n",
    "print('Cross Entropy Loss via numpy: \\n', output_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a438ab7-936f-425f-9559-3da7277da844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10) (60000,)\n",
      "Cross Entropy Loss via pytorch: \n",
      " tensor(2.3026, dtype=torch.float64)\n",
      "Cross Entropy Loss via manual: \n",
      " tensor(2.3026, dtype=torch.float64)\n",
      "Cross Entropy Loss via numpy: \n",
      " -2.3025850929940455\n"
     ]
    }
   ],
   "source": [
    "Z_tensor = torch.from_numpy(Z)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "print(Z.shape, y.shape)\n",
    "output_pytorch = loss_pytorch(Z_tensor, y_tensor)\n",
    "output_manual = loss_manual(Z_tensor, y_tensor)\n",
    "output_numpy = loss_numpy(Z,y)\n",
    "# print('input:\\n ', input)\n",
    "# print('target:\\n ', target)\n",
    "print('Cross Entropy Loss via pytorch: \\n', output_pytorch)\n",
    "print('Cross Entropy Loss via manual: \\n', output_manual)\n",
    "print('Cross Entropy Loss via numpy: \\n', output_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702fa36c-51f6-4234-9ef6-ca273920b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_loss(Z,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee4a90a-9c8a-48fb-b5ac-6710e3abe879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z = torch.from_numpy(Z)\n",
    "# y = torch.from_numpy(y)\n",
    "loss(Z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5b4935-6ad4-4f60-97e6-7c12a4107b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
