{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9cb3d66-42f9-45e1-abf4-21661357e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from src.simple_ml import *\n",
    "# Example of target with class indices\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numdifftools as nd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e85ffa-1c16-4a96-89f8-2045cfa1c2cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Exploring Parsing MNIST using python struct package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4ffa62-ee98-4a11-8e2a-4491c477d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(img):\n",
    "    \"\"\"\n",
    "    img: list with len = 784\n",
    "    An example image of MNIST dataset either train or test\n",
    "    \"\"\"\n",
    "    # Convert to numpy array\n",
    "    img = np.array(img)\n",
    "    # Reshape to 28x28 image to plot using matplotlib\n",
    "    img = img.reshape(28,28)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f981a634-57b0-475d-ba22-3bdce4ff2c99",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trying reading binary (rb) mode\n",
    "# ubyte is unsigned byte\n",
    "# idx3 means dimensions like n1xn2xn3; for MNIST train its 60,000 x 28 x 28\n",
    "# MNIST test is 10,000 x 28 x 28, we will convert this into 10,000 x 784\n",
    "\n",
    "path = 'data/t10k-images-idx3-ubyte.gz'\n",
    "with gzip.open(path,'rb') as f:\n",
    "    data = f.read() # returns a bytes object\n",
    "\n",
    "#### Format of the test images file\n",
    "# Train SET IMAGE FILE (train-images-idx3-ubyte):\n",
    "# |[offset] | [type]     |     [value]     |     [description]\n",
    "# 0000     32 bit integer  0x00000803(2051) magic number\n",
    "# 0004     32 bit integer  10000            number of images\n",
    "# 0008     32 bit integer  28               number of rows\n",
    "# 0012     32 bit integer  28               number of columns\n",
    "# 0016     unsigned byte   ??               pixel\n",
    "# 0017     unsigned byte   ??               pixel\n",
    "# ........\n",
    "# xxxx     unsigned byte   ??               pixel\n",
    "\n",
    "# For reading first 16 bytes, containing 4 bytes for magic number, 4 for #images, 4 for #rows and 4 for #cols \n",
    "meta_data = struct.iter_unpack('>I',data[0:16])\n",
    "\n",
    "magic_number = next(meta_data)\n",
    "n_images= next(meta_data)\n",
    "n_rows = next(meta_data)\n",
    "n_cols = next(meta_data)\n",
    "\n",
    "magic_number, n_images, n_rows, n_cols\n",
    "\n",
    "pixels = list(struct.iter_unpack('>B',data[16:]))\n",
    "\n",
    "len(list(pixels)) # 10000 x 784\n",
    "\n",
    "images = []\n",
    "n_pixels = n_rows[0] * n_cols[0]\n",
    "for i in range(n_images[0]):\n",
    "    images.append(pixels[i * n_pixels: i * n_pixels + n_pixels])\n",
    "\n",
    "assert len(images)==10000, \"Make sure there are 10,000 images in the test set\"\n",
    "\n",
    "visualize_image(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc50fc-91a5-4f9a-817d-584462634725",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trying reading binary (rb) mode\n",
    "# ubyte is unsigned byte\n",
    "# idx3 means dimensions like n1xn2xn3; for MNIST train its 60,000 x 28 x 28\n",
    "# MNIST test is 10,000 x 28 x 28, we will convert this into 10,000 x 784\n",
    "\n",
    "path = 'data/train-images-idx3-ubyte.gz'\n",
    "with gzip.open(path,'rb') as f:\n",
    "    data = f.read() # returns a bytes object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb0579c-53a2-4118-b8a2-d60ca3921d97",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_data = struct.iter_unpack('>I',data[0:16])\n",
    "magic_number, n_images, n_rows, n_cols = meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beabb3a1-baf9-4c3d-88a3-bd18080ace59",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "magic_number,n_images,n_rows,n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6648dd-f9cf-4184-95e3-c182b2029626",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Format of the test images file\n",
    "# Train SET IMAGE FILE (train-images-idx3-ubyte):\n",
    "# |[offset] | [type]     |     [value]     |     [description]\n",
    "# 0000     32 bit integer  0x00000803(2051) magic number\n",
    "# 0004     32 bit integer  10000            number of images\n",
    "# 0008     32 bit integer  28               number of rows\n",
    "# 0012     32 bit integer  28               number of columns\n",
    "# 0016     unsigned byte   ??               pixel\n",
    "# 0017     unsigned byte   ??               pixel\n",
    "# ........\n",
    "# xxxx     unsigned byte   ??               pixel\n",
    "\n",
    "# For reading first 16 bytes, containing 4 bytes for magic number, 4 for #images, 4 for #rows and 4 for #cols \n",
    "meta_data = struct.iter_unpack('>I',data[0:16])\n",
    "\n",
    "magic_number = next(meta_data)\n",
    "n_images= next(meta_data)\n",
    "n_rows = next(meta_data)\n",
    "n_cols = next(meta_data)\n",
    "\n",
    "magic_number, n_images, n_rows, n_cols\n",
    "\n",
    "pixels = list(struct.iter_unpack('>B',data[16:]))\n",
    "\n",
    "len(list(pixels)) # 10000 x 784\n",
    "\n",
    "images = []\n",
    "n_pixels = n_rows[0] * n_cols[0]\n",
    "for i in range(n_images[0]):\n",
    "    images.append(pixels[i * n_pixels: i * n_pixels + n_pixels])\n",
    "\n",
    "assert len(images)==60000, \"Make sure there are 10,000 images in the test set\"\n",
    "\n",
    "visualize_image(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e825d-414e-4c5b-8525-342b61355c20",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trying reading binary (rb) mode\n",
    "# ubyte is unsigned byte\n",
    "# idx3 means dimensions like n1xn2xn3; for MNIST train its 60,000 x 28 x 28\n",
    "# MNIST test is 10,000 x 28 x 28, we will convert this into 10,000 x 784\n",
    "\n",
    "path = 'data/train-labels-idx1-ubyte.gz'\n",
    "with gzip.open(path,'rb') as f:\n",
    "    data = f.read() # returns a bytes object\n",
    "\n",
    "#### Format of the test images file\n",
    "# Train SET label FILE (train-labels-idx1-ubyte):\n",
    "# [offset] [type]          [value]          [description]\n",
    "# 0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n",
    "# 0004     32 bit integer  10000            number of items\n",
    "# 0008     unsigned byte   ??               label\n",
    "# 0009     unsigned byte   ??               label\n",
    "# ........\n",
    "# xxxx     unsigned byte   ??               label\n",
    "# The labels values are 0 to 9.\n",
    "\n",
    "# For reading first 16 bytes, containing 4 bytes for magic number, 4 for #images, 4 for #rows and 4 for #cols \n",
    "meta_data = struct.iter_unpack('>I',data[0:8])\n",
    "\n",
    "magic_number = next(meta_data)\n",
    "n_labels = next(meta_data)\n",
    "\n",
    "\n",
    "train_labels = [label[0] for label in struct.iter_unpack('>B',data[8:])]\n",
    "\n",
    "assert len(train_labels)==n_labels[0], f\"Make sure there are {n_labels} labels in the test set, you currently have {len(train_labels)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca8ae0-f298-4a3f-926d-6b33056cb4ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trying reading binary (rb) mode\n",
    "# ubyte is unsigned byte\n",
    "# idx1 means dimensions like n1; for MNIST train its 60,000 for train\n",
    "# MNIST test is 10,000 x 1\n",
    "\n",
    "path = 'data/t10k-labels-idx1-ubyte.gz'\n",
    "with gzip.open(path,'rb') as f:\n",
    "    data = f.read() # returns a bytes object\n",
    "\n",
    "#### Format of the test images file\n",
    "# Test SET label FILE (test-labels-idx1-ubyte):\n",
    "# [offset] [type]          [value]          [description]\n",
    "# 0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n",
    "# 0004     32 bit integer  10000            number of items\n",
    "# 0008     unsigned byte   ??               label\n",
    "# 0009     unsigned byte   ??               label\n",
    "# ........\n",
    "# xxxx     unsigned byte   ??               label\n",
    "# The labels values are 0 to 9.\n",
    "\n",
    "# For reading first 16 bytes, containing 4 bytes for magic number, 4 for #images, 4 for #rows and 4 for #cols \n",
    "meta_data = struct.iter_unpack('>I',data[0:8])\n",
    "\n",
    "magic_number = next(meta_data)\n",
    "n_labels = next(meta_data)\n",
    "\n",
    "\n",
    "test_labels = [label[0] for label in struct.iter_unpack('>B',data[8:])]\n",
    "\n",
    "assert len(test_labels)==n_labels[0], f\"Make sure there are {n_labels} labels in the test set, you currently have {len(train_labels)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daabe02-63de-455e-813d-85a941fe9976",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_images(image_filename:str)->list:\n",
    "    print(f\"Working on {image_filename}\")\n",
    "    with gzip.open(image_filename,'rb') as f:\n",
    "        data = f.read() # returns a bytes object\n",
    "\n",
    "    #### Format of the test images file\n",
    "    # Train/Test SET IMAGE FILE (train[t10k]-images-idx3-ubyte):\n",
    "    # |[offset] | [type]     |     [value]     |     [description]\n",
    "    # 0000     32 bit integer  0x00000803(2051) magic number\n",
    "    # 0004     32 bit integer  60000(10000)     number of train(test)images\n",
    "    # 0008     32 bit integer  28               number of rows\n",
    "    # 0012     32 bit integer  28               number of columns\n",
    "    # 0016     unsigned byte   ??               pixel\n",
    "    # 0017     unsigned byte   ??               pixel\n",
    "    # ........\n",
    "    # xxxx     unsigned byte   ??               pixel\n",
    "\n",
    "    # For reading first 16 bytes, containing 4 bytes for magic number, 4 for #images, 4 for #rows and 4 for #cols \n",
    "    meta_data = struct.iter_unpack('>I',data[0:16])\n",
    "\n",
    "    magic_number, n_images, n_rows, n_cols  = meta_data\n",
    "\n",
    "    pixels = [pix[0] for pix in struct.iter_unpack('>B',data[16:])]\n",
    "\n",
    "    images = []\n",
    "    n_pixels = n_rows[0] * n_cols[0]\n",
    "    n_images = n_images[0]\n",
    "    assert len(list(pixels))==n_images*n_pixels # 60000(10000) x 784\n",
    "    \n",
    "    for i in range(n_images):\n",
    "        images.append(pixels[i * n_pixels: i * n_pixels + n_pixels])\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda5dc2-97a1-4c59-afff-72b2ad758b0e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_labels(label_filename:str)->list:\n",
    "    print(f\"Working on {label_filename}\")\n",
    "    with gzip.open(label_filename,'rb') as f:\n",
    "        data = f.read() # returns a bytes object\n",
    "\n",
    "    #### Format of the test images file\n",
    "    # Train/test SET label FILE (train(t10k)-labels-idx1-ubyte):\n",
    "    # [offset] [type]          [value]          [description]\n",
    "    # 0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n",
    "    # 0004     32 bit integer  60000(10000)     number of items\n",
    "    # 0008     unsigned byte   ??               label\n",
    "    # 0009     unsigned byte   ??               label\n",
    "    # ........\n",
    "    # xxxx     unsigned byte   ??               label\n",
    "    # The labels values are 0 to 9.\n",
    "\n",
    "    # For reading first 8 bytes, containing 4 bytes for magic number, 4 for #labels\n",
    "    meta_data = struct.iter_unpack('>I',data[0:8])\n",
    "\n",
    "    magic_number = next(meta_data)\n",
    "    n_labels = next(meta_data)\n",
    "\n",
    "    labels = [label[0] for label in struct.iter_unpack('>B',data[8:])]\n",
    "\n",
    "    assert len(labels)==n_labels[0], f\"Make sure there are {n_labels} labels in the test set,\\\n",
    "                                       you currently have {len(labels)}\"\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44cb48-3151-4d50-97d3-c175ae0ce21f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_mnist(image_filename, label_filename):\n",
    "    \"\"\" Read an images and labels file in MNIST format.  See this page:\n",
    "    http://yann.lecun.com/exdb/mnist/ for a description of the file format.\n",
    "\n",
    "    Args:\n",
    "        image_filename (str): name of gzipped images file in MNIST format\n",
    "        label_filename (str): name of gzipped labels file in MNIST format\n",
    "\n",
    "    Returns:\n",
    "        Tuple (X,y):\n",
    "            X (numpy.ndarray[np.float32]): 2D numpy array containing the loaded\n",
    "                data.  The dimensionality of the data should be\n",
    "                (num_examples x input_dim) where 'input_dim' is the full\n",
    "                dimension of the data, e.g., since MNIST images are 28x28, it\n",
    "                will be 784.  Values should be of type np.float32, and the data\n",
    "                should be normalized to have a minimum value of 0.0 and a\n",
    "                maximum value of 1.0.\n",
    "\n",
    "            y (numpy.ndarray[dypte=np.uint8]): 1D numpy array containing the\n",
    "                labels of the examples.  Values should be of type np.uint8 and\n",
    "                for MNIST will contain the values 0-9.\n",
    "    \"\"\"\n",
    "    ### BEGIN YOUR CODE\n",
    "    if  \"train\" in image_filename:\n",
    "        assert \"train-labels\" in label_filename, \"Please pass labels for train images only.\"\n",
    "        images = parse_images(image_filename)\n",
    "        labels = parse_labels(label_filename)\n",
    "        train_images = np.array(images, dtype=np.float32)\n",
    "        # normalize the images between 0 and 1\n",
    "        #train_images = train_images/np.linalg.norm(train_images)\n",
    "        train_labels = np.array(labels, dtype=np.uint8)\n",
    "        return (train_images, train_labels)\n",
    "    \n",
    "    if  \"test\" in image_filename:\n",
    "        assert \"t10k-labels\" in label_filename, \"Please pass labels for test images only.\"\n",
    "        images = parse_images(image_filename)\n",
    "        labels = parse_labels(label_filename)\n",
    "        #test_images = np.array(images, dtype=np.float32)\n",
    "        # normalize the images between 0 and 1\n",
    "        test_images = test_images/np.linalg.norm(test_images)\n",
    "        test_labels = np.array(labels, dtype=np.uint8)\n",
    "        return (test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d787a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = simple_ml.parse_mnist(\"data/train-images-idx3-ubyte.gz\",\n",
    "            \"data/train-labels-idx1-ubyte.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55a993f-e987-4e1b-b6ba-b43275bb16b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e8a62d4-48c9-40e0-9e9a-ab3f472b105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros((y.shape[0], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877eb818-be06-456e-8ba5-751fa2b16a7b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Z = np.random.randn(y.shape[0], 10)\n",
    "\n",
    "# Z.shape, y.shape\n",
    "\n",
    "# (np.argmax(Z, axis=1)==y).shape\n",
    "\n",
    "# np.argmax(Z, axis=1).shape, np.max(y)\n",
    "\n",
    "# np.mean(np.log(np.sum(np.exp(Z),axis=1)))\n",
    "\n",
    "# np.mean(np.argmax(Z, axis=1)==y)\n",
    "\n",
    "# np.mean(np.log(np.sum(np.exp(Z),axis=1))) \n",
    "\n",
    "# loss = np.mean(np.log(np.sum(np.exp(Z),axis=1)) - ((np.argmax(Z, axis=1)+1==y+1)))\n",
    "\n",
    "# loss\n",
    "\n",
    "# np.mean(loss, dtype=np.float32)\n",
    "\n",
    "# e_x = np.exp(Z - np.max(Z))\n",
    "# softmax = np.log(e_x / e_x.sum())\n",
    "\n",
    "# np.mean(np.mean(softmax) - (np.argmax(Z, axis=1)==y))\n",
    "\n",
    "# Z = np.random.randn(y.shape[0], 10)\n",
    "\n",
    "# np.mean(np.log(np.sum(np.exp(Z),axis=1)) - (np.argmax(Z, axis=1)==y))\n",
    "\n",
    "# np.argmax(Z, axis=1).shape, y.shape\n",
    "\n",
    "# type(y), type(np.argmax(Z,axis=0))\n",
    "\n",
    "# np.mean(np.log(np.sum(np.exp(Z),axis=1)) - np.equal(np.argmax(Z, axis=1),y))\n",
    "\n",
    "# np.sum(Z,axis=1).shape\n",
    "\n",
    "# np.argmax(Z[0:10],axis=1)\n",
    "\n",
    "# max_Z = np.max(Z)\n",
    "# max_Z\n",
    "\n",
    "# exp_Z = np.exp(Z - max_Z)\n",
    "# exp_Z.shape\n",
    "\n",
    "# sum_exp_Z = np.sum(exp_Z,axis=0)\n",
    "# log_sum_exp_Z = np.log(sum_exp_Z)\n",
    "# max_plus_log_sum_exp_Z = max_Z + log_sum_exp_Z\n",
    "# max_plus_log_sum_exp_Z.shape\n",
    "\n",
    "# Z.max()\n",
    "\n",
    "# max_plus_log_sum_exp_Z\n",
    "\n",
    "# log_probs = Z - max_plus_log_sum_exp_Z\n",
    "\n",
    "# log_probs\n",
    "\n",
    "# np.mean(np.log(np.sum(np.exp(Z),axis=1)) - (np.argmax(Z, axis=1)==y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897bacc-06ff-45f0-a8ac-07d0fc94fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    exps = np.exp(X)\n",
    "    return exps / np.sum(exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a1365-d4e6-4af0-af37-758779a4d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_softmax(X):\n",
    "    exps = np.exp(X - np.max(X))\n",
    "    return exps / np.sum(exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0598cf-dac5-4b38-b4cb-b973be3120bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = y.shape[0]\n",
    "p = softmax(Z)\n",
    "# We use multidimensional array indexing to extract \n",
    "# softmax probability of the correct label for each sample.\n",
    "# Refer to https://docs.scipy.org/doc/numpy/user/basics.indexing.html#indexing-multi-dimensional-arrays for understanding multidimensional array indexing.\n",
    "log_likelihood = -np.log(p[range(m),y])\n",
    "loss = np.sum(log_likelihood) / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e271a4-3ced-4a06-889b-a0c5be6816f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b0f37f-40e7-4266-8a77-25c7c90141be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nll_loss(log_softmax(input, 1), target, weight, size_average, ignore_index, reduce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e24d14-93c7-4bdd-a9cd-cbe5c95e436d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Exploring the softmax loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5638f74c-a5bc-4425-99fb-88b06719f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference:\n",
    "#https://stackoverflow.com/questions/70202761/manually-computing-cross-entropy-loss-in-pytorch\n",
    "class CrossEntropyLossManual:\n",
    "    \"\"\"\n",
    "    Z is the vector with shape (batch_size,C)\n",
    "    y shape is the same (batch_size), whose entries are integers from 0 to C-1\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def __call__(self, Z, y):\n",
    "        loss = 0.\n",
    "        n_batch, n_class = Z.shape\n",
    "        #numerator, denominator, softmax, log_softmax = [],[],[],[]\n",
    "        #print(n_batch,n_class)\n",
    "        for z1, y1 in zip(Z, y):\n",
    "            #print(z1,y1)\n",
    "            class_index = int(y1.item())\n",
    "            # numerator.append(torch.exp(z1[class_index]))\n",
    "            # denominator.append(torch.exp(z1).sum())\n",
    "            # softmax.append(torch.exp(z1[class_index])/(torch.exp(z1).sum()))\n",
    "            # log_softmax.append(torch.log(torch.exp(z1[class_index])/(torch.exp(z1).sum())))\n",
    "            loss = loss + torch.log(torch.exp(z1[class_index])/(torch.exp(z1).sum()))\n",
    "        # print(f\"Numerator calcualted by loss_manual is {numerator}\")\n",
    "        # print(f\"Denominator calcualted by loss_manual is {denominator}\")\n",
    "        # print(f\"Softmax calcualted by loss_manual is {softmax}\")\n",
    "        # print(f\"Log-Softmax calcualted by loss_manual is {log_softmax}\")\n",
    "        # print(f\"Loss before average by loss_manual is {loss}\")\n",
    "        loss = - loss/n_batch\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b8382fd-d00d-4619-9439-860b4189eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_numpy(input, target):\n",
    "    numerator = np.exp(input[range(input.shape[0]),target])\n",
    "    #print(f\"Numerator calcualted by loss_numpy is {numerator}\")\n",
    "    denominator = np.sum(np.exp(input), axis=1)\n",
    "    #print(f\"Denominator calcualted by loss_numpy is {denominator}\")\n",
    "    softmax = numerator/denominator\n",
    "    #print(f\"Softmax calcualted by loss_numpy is {softmax}\")\n",
    "    log_softmax = np.log(softmax)\n",
    "    #print(f\"Log-Softmax calcualted by loss_numpy is {log_softmax}\")\n",
    "    loss = np.mean(log_softmax)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d294c-4cf0-4f4f-be0e-ea63fb06badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.log(np.exp(input[range(input.shape[0]),target])/np.sum(np.exp(input), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6796c8a5-ca1b-45f8-88f4-26aa0257ee7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(3, 5)\n",
    "target = torch.empty(3, dtype = torch.long).random_(5)\n",
    "print(input.shape,target.shape)\n",
    "input_np = input.numpy()\n",
    "target_np = target.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79ca8452-6ce4-4e0c-a481-d7d5c9f48994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss via manual: \n",
      " tensor(1.7306)\n",
      "Cross Entropy Loss via numpy: \n",
      " -1.7306296\n"
     ]
    }
   ],
   "source": [
    "loss_manual = CrossEntropyLossManual()\n",
    "output_manual = loss_manual(input, target)\n",
    "output_numpy = loss_numpy(input_np,target_np)\n",
    "print('Cross Entropy Loss via manual: \\n', output_manual)\n",
    "print('Cross Entropy Loss via numpy: \\n', output_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7b864cd-6e55-41df-964a-535c39e58d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "  tensor([[0.4009, 0.5387, 0.2455, 0.1033, 0.6917],\n",
      "        [0.5332, 0.1734, 0.7952, 0.8132, 0.7162],\n",
      "        [0.2048, 0.5878, 0.9979, 0.6212, 0.8195]])\n",
      "target:\n",
      "  tensor([2, 0, 1])\n",
      "Cross Entropy Loss via pytorch: \n",
      " tensor(1.7306)\n",
      "Cross Entropy Loss via manual: \n",
      " tensor(1.7306)\n",
      "Cross Entropy Loss via numpy: \n",
      " -1.7306296\n"
     ]
    }
   ],
   "source": [
    "loss_manual = CrossEntropyLossManual()\n",
    "loss_pytorch = nn.CrossEntropyLoss()\n",
    "output_pytorch = loss_pytorch(input, target)\n",
    "output_manual = loss_manual(input, target)\n",
    "output_numpy = loss_numpy(input_np,target_np)\n",
    "print('input:\\n ', input)\n",
    "print('target:\\n ', target)\n",
    "print('Cross Entropy Loss via pytorch: \\n', output_pytorch)\n",
    "print('Cross Entropy Loss via manual: \\n', output_manual)\n",
    "print('Cross Entropy Loss via numpy: \\n', output_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a438ab7-936f-425f-9559-3da7277da844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10) (60000,)\n",
      "Cross Entropy Loss via pytorch: \n",
      " tensor(2.3026, dtype=torch.float64)\n",
      "Cross Entropy Loss via manual: \n",
      " tensor(2.3026, dtype=torch.float64)\n",
      "Cross Entropy Loss via numpy: \n",
      " -2.3025850929940455\n"
     ]
    }
   ],
   "source": [
    "Z_tensor = torch.from_numpy(Z)\n",
    "y_tensor = torch.from_numpy(y)\n",
    "print(Z.shape, y.shape)\n",
    "output_pytorch = loss_pytorch(Z_tensor, y_tensor)\n",
    "output_manual = loss_manual(Z_tensor, y_tensor)\n",
    "output_numpy = loss_numpy(Z,y)\n",
    "# print('input:\\n ', input)\n",
    "# print('target:\\n ', target)\n",
    "print('Cross Entropy Loss via pytorch: \\n', output_pytorch)\n",
    "print('Cross Entropy Loss via manual: \\n', output_manual)\n",
    "print('Cross Entropy Loss via numpy: \\n', output_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702fa36c-51f6-4234-9ef6-ca273920b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_loss(Z,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee4a90a-9c8a-48fb-b5ac-6710e3abe879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z = torch.from_numpy(Z)\n",
    "# y = torch.from_numpy(y)\n",
    "loss(Z,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6aea61-1da6-4694-9bd3-98bf0b0df18c",
   "metadata": {},
   "source": [
    "### Exploring numpy functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99a28966-4270-4703-b6fb-07a517662727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.30685282, 2.        , 0.30685282, 0.30685282, 3.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randint(10,size=5)\n",
    "b = np.random.randint(1,3,size=5)\n",
    "np.log(np.exp(a)/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "921a98f2-5cbd-48eb-a95f-c97b2bccd203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e38ba8-dd4b-43bc-9f6a-b6d6839dd352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718281828459045"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c576e6b6-df2f-42b5-b748-748d7ed5e6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(3, 10) # represents 3 examples, each with 10 features\n",
    "target = torch.empty(3, dtype = torch.long).random_(4) #represents 4 classes in the data\n",
    "print(input.shape,target.shape)\n",
    "input_np = input.numpy()\n",
    "target_np = target.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d55814b1-4e73-4a77-a046-e9387b91f3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51bfa975-f9ff-4da3-8ce8-61d49007237d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.71828183, 20.08553692,  1.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(target_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe148959-e5c6-4641-82d3-c8229a3b8ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.803818751646713"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.exp(target_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "458ff62a-97e1-4eff-9a34-c7bbcd41596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_softmax = target_np - np.log(np.sum(np.exp(target_np)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4093959-ab07-4fa7-973b-e924c7f7056b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.16984602, -0.16984602, -3.16984602])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7989e97e-005c-47b6-9981-04a57a6702ca",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\ell_{\\mathrm{softmax}}(z, y) = \\log\\sum_{i=1}^k \\exp z_i - z_y.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c91f6861-7225-4c16-a7a4-e2123b6d2fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22063055, 0.71128048, 0.10020596],\n",
       "       [0.97143822, 0.59815188, 0.13750278],\n",
       "       [0.79228972, 0.02759386, 0.83471661],\n",
       "       [0.59853255, 0.78788152, 0.36687649],\n",
       "       [0.58836817, 0.9153712 , 0.35075371]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume we have 5 examples, 2 features/input-size, 3 classes\n",
    "# z is the number of examples x prob. of each class i.e. 5 x 3 here\n",
    "# This is the output of the batch of the neural network\n",
    "z = np.random.rand(5,3)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cb8294c-c3c6-49bb-8916-ac90623f83ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 0, 1, 2, 0]), (5,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels is the label for each example in the batch i.e. 5x1\n",
    "labels = np.random.randint(0,3, size=5)\n",
    "labels, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba8e6f64-3496-4c3d-8c5e-a665b093d328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.47906921, 1.7241764 , 1.71210035, 1.69770518, 1.74377417]), (5,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = np.exp(z) # 5 x 3\n",
    "sum_exp = np.sum(exp, axis=1) # 5 x 1\n",
    "log_sum_exp = np.log(sum_exp) # 5 x 1\n",
    "log_sum_exp, log_sum_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35e8c33e-2670-4f2b-84f4-095126d0427d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71128048, 0.13750278])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multi-dimensional indexing z is of shape (n_examples, n_classes) i.e. 5x3\n",
    "# Selecting the probability of first,second example being of Class 1,2\n",
    "z[[0,1],[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ffce2fc-de11-488c-8634-4fc6186aa8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.10020596, 0.97143822, 0.02759386, 0.36687649, 0.58836817]), (5,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the probability predicted by the NN (stored in Z (5x3))\n",
    "# as opposed to actual label of the example (stored in y (5x1))\n",
    "# Use multi-dimensional indexing in numpy for brevity\n",
    "z_y = z[list(range(5)), labels] # 5 x 1\n",
    "z_y,z_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "528308b9-42f6-430c-95c6-6d6409ecc1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.37886325 0.75273818 1.68450649 1.33082869 1.155406  ] (5,)\n",
      "-1.2604685212531055\n"
     ]
    }
   ],
   "source": [
    "log_softmax = log_sum_exp - z_y # 5 x 1\n",
    "avg_log_softmax = - np.mean(log_softmax)\n",
    "print(log_softmax,log_softmax.shape)\n",
    "print(avg_log_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4c18c59-6465-4a8c-aed6-c34b22feb7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2604685212531055"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check with reference solution\n",
    "- np.mean(np.log(np.exp(z[range(z.shape[0]),labels])/np.sum(np.exp(z), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68279aee-d7f6-47d6-85b6-da4e6b78c1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.2604685212531055"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One liner solution \n",
    "- np.mean(np.log(np.sum(np.exp(z),axis=1)) - z[range(z.shape[0]),labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d914fc7-daff-435d-8899-18e61814e423",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exploring Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf8d0a8-a916-4078-8e28-aa62dd827c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume we have 5 examples, 10 features/input-size, 3 classes\n",
    "# z is the number of examples x prob. of each class i.e. 5 x 3 here\n",
    "# This is the output of the batch of the neural network\n",
    "X = np.random.rand(5,10)\n",
    "y = np.random.randint(0,3,size=5)\n",
    "batch = 2\n",
    "theta = np.random.rand(10,3) # weights of size (input_dimensions x n_classes)\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ee69ae-4a09-49b9-9d80-bde540173508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_loss(Z, y):\n",
    "    \"\"\" Return softmax loss.  Note that for the purposes of this assignment,\n",
    "    you don't need to worry about \"nicely\" scaling the numerical properties\n",
    "    of the log-sum-exp computation, but can just compute this directly.\n",
    "\n",
    "    Args:\n",
    "        Z (np.ndarray[np.float32]): 2D numpy array of shape\n",
    "            (batch_size, num_classes), containing the logit predictions for\n",
    "            each class.\n",
    "        y (np.ndarray[np.int8]): 1D numpy array of shape (batch_size, )\n",
    "            containing the true label of each example.\n",
    "\n",
    "    Returns:\n",
    "        Average softmax loss over the sample.\n",
    "    \"\"\"\n",
    "    # Reference https://stackoverflow.com/questions/70202761/manually-computing-cross-entropy-loss-in-pytorch\n",
    "    ### BEGIN YOUR CODE\n",
    "    # simple log softmax \n",
    "    # return - np.mean(np.log(np.exp(Z[range(Z.shape[0]),y])/np.sum(np.exp(Z), axis=1)))\n",
    "    # stable log-softmax without the need of division (so no divide by zero error)\n",
    "    return np.mean(np.log(np.sum(np.exp(Z),axis=1)) - Z[range(Z.shape[0]),y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eddf330-778b-4e35-a683-c302075fed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using array indexing to divide X into equally sized batches\n",
    "def softmax_regression_epoch(X,y,theta,lr=1.0,batch=50):\n",
    "    if (X.shape[0]%batch):\n",
    "        n_iterations = X.shape[0]//batch + 1\n",
    "    else: \n",
    "        n_iterations = X.shape[0]//batch\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        mini_batch = X[i*batch: i*batch + batch] # Take the batch out, batch_size x number of features\n",
    "        mini_batch_targets = y[i*batch: i*batch + batch]\n",
    "        output = np.matmul(mini_batch, theta) # batch_size x n_classes\n",
    "        z = np.exp(output)/np.sum(np.exp(output),axis=0) # normalize wrt rows, batch_size x n_classes\n",
    "        a = np.zeros((mini_batch_targets.size,y.max()+1))\n",
    "        a[range(mini_batch_targets.size),mini_batch_targets] = 1 # one-hot encoding; batch_size x n_classes\n",
    "        b = z - a\n",
    "        temp = np.matmul(mini_batch.T, b) \n",
    "        theta -= lr * temp # modifying in-place, n_features x n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e8335f-cd54-4eda-8e87-9463d9fd4c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.0916562  -7.5612955   5.166902  ]\n",
      " [ 3.5317361  -1.8526123   5.4791226 ]\n",
      " [ 2.44782     0.62592995 -2.310427  ]\n",
      " [-3.9415877   2.3346987   1.1991554 ]\n",
      " [ 2.6594627   2.4838834   0.29733157]]\n",
      "[[-0.02525946 -0.11465225  0.13991171]\n",
      " [ 0.02291308 -0.08477389  0.06186081]\n",
      " [ 0.04386758  0.00742978 -0.05129736]\n",
      " [-0.07611353  0.0494122   0.02670133]\n",
      " [ 0.01691807  0.01340648 -0.03032455]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.0001, atol=0.0001\n\nMismatched elements: 15 / 15 (100%)\nMax absolute difference: 7.44664326\nMax relative difference: 1.10198901\n x: array([[-0.025259, -0.114652,  0.139912],\n       [ 0.022913, -0.084774,  0.061861],\n       [ 0.043868,  0.00743 , -0.051297],...\n y: array([[-3.091656, -7.561296,  5.166902],\n       [ 3.531736, -1.852612,  5.479123],\n       [ 2.44782 ,  0.62593 , -2.310427],...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(Theta)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(dTheta\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdTheta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/numpy/testing/_private/utils.py:844\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    840\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remarks)\n\u001b[1;32m    841\u001b[0m         msg \u001b[38;5;241m=\u001b[39m build_err_msg([ox, oy], err_msg,\n\u001b[1;32m    842\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    843\u001b[0m                             names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[0;32m--> 844\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.0001, atol=0.0001\n\nMismatched elements: 15 / 15 (100%)\nMax absolute difference: 7.44664326\nMax relative difference: 1.10198901\n x: array([[-0.025259, -0.114652,  0.139912],\n       [ 0.022913, -0.084774,  0.061861],\n       [ 0.043868,  0.00743 , -0.051297],...\n y: array([[-3.091656, -7.561296,  5.166902],\n       [ 3.531736, -1.852612,  5.479123],\n       [ 2.44782 ,  0.62593 , -2.310427],..."
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randn(50,5).astype(np.float32)\n",
    "y = np.random.randint(3, size=(50,)).astype(np.uint8)\n",
    "Theta = np.zeros((5,3), dtype=np.float32)\n",
    "dTheta = -nd.Gradient(lambda Th : softmax_loss(X@Th.reshape(5,3),y))(Theta)\n",
    "softmax_regression_epoch(X,y,Theta,lr=1.0,batch=50)\n",
    "print(Theta)\n",
    "print(dTheta.reshape(5,3))\n",
    "np.testing.assert_allclose(dTheta.reshape(5,3), Theta, rtol=1e-4, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e26bd90-eb6d-4d72-ad62-17c85b532eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10)\n",
      "(2, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,3) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(test_batch, theta)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,3) (2,) "
     ]
    }
   ],
   "source": [
    "test_batch = X[0:2]\n",
    "print(test_batch.shape)\n",
    "output = np.matmul(test_batch, theta)\n",
    "print(output.shape)\n",
    "np.exp(output)/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8df3caf-3207-4cad-a5a5-c414f66e510b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46876614, 0.4288653 , 0.42054245, 0.50892158, 0.49846952,\n",
       "        0.32217456, 0.58762212, 0.31426216, 0.64452526, 0.46206821],\n",
       "       [0.53123386, 0.5711347 , 0.57945755, 0.49107842, 0.50153048,\n",
       "        0.67782544, 0.41237788, 0.68573784, 0.35547474, 0.53793179]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.exp(test_batch)/np.sum(np.exp(test_batch),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0aa7344-e053-4c4c-8b7d-9426b64b557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets = y[0:2]\n",
    "print(test_targets)\n",
    "a = np.zeros((test_targets.size,3))\n",
    "a[range(2),test_targets] = 1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5bd62-be2c-44a0-a54b-3468fadac24c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
